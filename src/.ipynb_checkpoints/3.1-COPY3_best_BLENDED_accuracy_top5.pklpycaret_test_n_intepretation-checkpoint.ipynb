{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "%matplotlib inline\n",
    "from pycaret.classification import *\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLOBAL PATH VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook folder\n",
    "NB_DIR = %pwd\n",
    "NB_DIR = Path(NB_DIR)\n",
    "\n",
    "# Root MCI foler\n",
    "ROOT_DIR = NB_DIR.parent\n",
    "\n",
    "# Main data folder (with downloaded csv files)\n",
    "MAIN_DATA_DIR = ROOT_DIR/'data'\n",
    "DATA_DIR_FS = ROOT_DIR / 'data_FS'\n",
    "\n",
    "# Current data dir with sMCI_cAD.csv & bl.csv files\n",
    "CURRENT_DATA_DIR = ROOT_DIR/'results'\n",
    "\n",
    "# Results folder\n",
    "RESULTS_DIR = ROOT_DIR/'results' #misclassified patient table\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMOPRTS TO CREATE CONFUSION MATRIX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"/modules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages needed\n",
    "import mci_rf_bl as mrfbl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting to displaying all columns in pandas df\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generated in RandomForest-notebook\n",
    "dataset = pd.read_csv(RESULTS_DIR /'2.0-random_forest_train_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.loc[dataset.Usage_=='train']\n",
    "data_unseen = dataset.loc[dataset.Usage_=='test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>RAVLT_immediate</th>\n",
       "      <th>AVDEL30MIN_neuro</th>\n",
       "      <th>AVDELTOT_neuro</th>\n",
       "      <th>TRAASCOR_neuro</th>\n",
       "      <th>TRABSCOR_neuro</th>\n",
       "      <th>CATANIMSC_neuro</th>\n",
       "      <th>GDTOTAL_gds</th>\n",
       "      <th>ANARTERR_neuro</th>\n",
       "      <th>LRHHC_n_long</th>\n",
       "      <th>Apoe4_</th>\n",
       "      <th>Subgroup_</th>\n",
       "      <th>Subgroup_num_</th>\n",
       "      <th>Usage_</th>\n",
       "      <th>PTGENDER</th>\n",
       "      <th>Gender_num_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>80.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sMCI</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>77.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.003343</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cAD</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>77.5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.003149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cAD</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>71.1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.003729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cAD</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>83.6</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cAD</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AGE  RAVLT_immediate  AVDEL30MIN_neuro  AVDELTOT_neuro  TRAASCOR_neuro  \\\n",
       "6    80.4             30.0               1.0             7.0            49.0   \n",
       "82   77.3             29.0               0.0            11.0           122.0   \n",
       "184  77.5             35.0               1.0            10.0            27.0   \n",
       "359  71.1             24.0               0.0             2.0            50.0   \n",
       "384  83.6             30.0               2.0             9.0            22.0   \n",
       "\n",
       "     TRABSCOR_neuro  CATANIMSC_neuro  GDTOTAL_gds  ANARTERR_neuro  \\\n",
       "6             168.0             13.0          0.0            17.0   \n",
       "82            151.0             17.0          2.0             3.0   \n",
       "184            69.0             24.0          2.0            22.0   \n",
       "359            85.0             13.0          2.0             7.0   \n",
       "384            76.0             18.0          0.0             9.0   \n",
       "\n",
       "     LRHHC_n_long  Apoe4_ Subgroup_  Subgroup_num_ Usage_ PTGENDER  \\\n",
       "6        0.003638     0.0      sMCI              0   test   Female   \n",
       "82       0.003343     1.0       cAD              1   test     Male   \n",
       "184      0.003149     1.0       cAD              1   test   Female   \n",
       "359      0.003729     0.0       cAD              1   test   Female   \n",
       "384      0.003700     0.0       cAD              1   test   Female   \n",
       "\n",
       "     Gender_num_  \n",
       "6              1  \n",
       "82             0  \n",
       "184            1  \n",
       "359            1  \n",
       "384            1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_unseen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for Modeling: (539, 16)\n",
      "Unseen Data For Predictions: (139, 16)\n"
     ]
    }
   ],
   "source": [
    "print('Data for Modeling: ' + str(data.shape))\n",
    "print('Unseen Data For Predictions: ' + str(data_unseen.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the best PyCaret model created in `3.0-pycaret_pipeline`-notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f54c583cfccd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mensemble_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRESULTS_DIR\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m'2COPY_best_blended_accuracy_top5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/pycaret/classification.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(model_name, platform, authentication, verbose)\u001b[0m\n\u001b[1;32m   2201\u001b[0m     \"\"\"\n\u001b[1;32m   2202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2203\u001b[0;31m     return pycaret.internal.tabular.load_model(\n\u001b[0m\u001b[1;32m   2204\u001b[0m         \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m         \u001b[0mplatform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplatform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(model_name, platform, authentication, verbose)\u001b[0m\n\u001b[1;32m   9295\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9297\u001b[0;31m     return pycaret.internal.persistence.load_model(\n\u001b[0m\u001b[1;32m   9298\u001b[0m         \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplatform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthentication\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9299\u001b[0m     )\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/pycaret/internal/persistence.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(model_name, platform, authentication, verbose)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Transformation Pipeline and Model Successfully Loaded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;31m# cloud providers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    583\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mload_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             warnings.warn(\"The file '%s' has been generated with a \"\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1208\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1210\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1211\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36mload_global\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1525\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1526\u001b[0;31m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1527\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1528\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGLOBAL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_global\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36mfind_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m   1575\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_compat_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMPORT_MAPPING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compat_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMPORT_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m         \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1578\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_getattribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "ensemble_model = load_model(RESULTS_DIR /'2COPY_best_blended_accuracy_top5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function pycaret.classification.ensemble_model(estimator, method: str = 'Bagging', fold: Union[int, Any, NoneType] = None, n_estimators: int = 10, round: int = 4, choose_better: bool = False, optimize: str = 'Accuracy', fit_kwargs: Union[dict, NoneType] = None, groups: Union[str, Any, NoneType] = None, verbose: bool = True) -> Any>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using this model to predict on unseen test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ensemble = predict_model(ensemble_model, data=data_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ensemble.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tolk resultater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Finn tp, fp, fn, tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unseen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ensemble.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding column `Ens_pred` for further comparison with predictions from Random Forest model (below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ensemble['Ens_pred'] = \"\" \n",
    "\n",
    "for i in preds_ensemble.index:\n",
    "    \n",
    "    if preds_ensemble.loc[i,'Ens_pred'] == \"\":\n",
    "\n",
    "        if preds_ensemble.loc[i, 'Subgroup_'] == 'sMCI' and preds_ensemble.loc[i, 'Label'] == 0:\n",
    "            preds_ensemble.loc[i, 'Ens_pred'] = 'TN_'\n",
    "\n",
    "        elif preds_ensemble.loc[i, 'Subgroup_'] == 'sMCI' and preds_ensemble.loc[i, 'Label'] == 1:\n",
    "            preds_ensemble.loc[i, 'Ens_pred'] ='FP_' \n",
    "\n",
    "        elif preds_ensemble.loc[i, 'Subgroup_'] == 'cAD' and preds_ensemble.loc[i, 'Label'] == 0:\n",
    "            preds_ensemble.loc[i, 'Ens_pred'] = 'FN_' \n",
    "\n",
    "        elif preds_ensemble.loc[i, 'Subgroup_'] == 'cAD' and preds_ensemble.loc[i, 'Label'] == 1:\n",
    "            preds_ensemble.loc[i, 'Ens_pred'] ='TP_' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual inspection for minimum one of each prediction (aka TN_, FP_ FN_ & TP_)\n",
    "# If 'Subgroup_' == 'sMCI' and 'Label' == 1, then 'Ens_pred' should be 'FP_'\n",
    "preds_ensemble.head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive and negative predictions\n",
    "p = preds_ensemble.loc[preds_ensemble.Label == 1]\n",
    "n = preds_ensemble.loc[preds_ensemble.Label == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn = len(preds_ensemble.loc[preds_ensemble['Ens_pred'] == 'TN_'])\n",
    "fp = len(preds_ensemble.loc[preds_ensemble['Ens_pred'] == 'FP_'])\n",
    "fn = len(preds_ensemble.loc[preds_ensemble['Ens_pred'] == 'FN_'])\n",
    "tp = len(preds_ensemble.loc[preds_ensemble['Ens_pred'] == 'TP_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misclassification FP + FN / TP + TN + FP + FN\n",
    "misclass_perc = (fp + fn) / (tp + tn + fp + fn)\n",
    "print(f\"Percentage of test set misclassified: {misclass_perc}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy (TP + TN) / (TP + TN + FP + FN)\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "print(f\"Accuracyen for classification on test set: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision TP / TP + FP\n",
    "precision = tp / (tp + fp)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity aka Recall (true positives / all actual positives) = TP / TP + FN\n",
    "recall = tp / (tp + fn)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity TP / (TP + FN)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specificity (true negatives / all actual negatives) = TN / TN + FP\n",
    "specificity = tn / (tn + fp)\n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating confusion matrix for Ensemble's prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepareing 'y_true' from ensemble's prediction --> this is ground truth\n",
    "y_test = preds_ensemble.Subgroup_num_\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing y_test_pred from ansemble --> this is from 'Label' column\n",
    "y_test_pred = preds_ensemble.Label\n",
    "y_test_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting confusion matrix for test set \n",
    "conf_matrix_test_ens  = metrics.confusion_matrix(y_test, y_test_pred)\n",
    "conf_matrix_test_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of test confusion matix \n",
    "# conf_mat_mean = conf_matrix_test_ens.mean(axis=0)\n",
    "# percantage values of confusion matix according to validatin set lenght\n",
    "\n",
    "conf_matrix_test_prc = conf_matrix_test_ens / y_test.shape[0] * 100\n",
    "\n",
    "conf_mat_ens = mrfbl.plot_confusion_matrix_TEST_IR(conf_matrix_test_ens, conf_matrix_test_prc,\n",
    "                                    file_name_number=\"K50\", title=\"Ensemble model\",\n",
    "                                    file_name_prefix=\"3.1-ensemble-conf-matrix\",\n",
    "                                    save=True, results_dir=RESULTS_DIR/'figs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data with predictions from Random Forest for further comparison. \n",
    "### File: `results/RandomForest-CV50-predictions.csv`\n",
    "Loading data frame containing information about the Random Forest model's classification on test set. \n",
    "\n",
    "Prediction (i.e TN, FP, FN or TP) is specified by `CM_pred_`-column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = pd.read_csv(RESULTS_DIR / '2.0-random_forest-TEST-predictions.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict to features needed for further analysis, all meta data is in 'Preds_ensemble'-file\n",
    "rf_pred = rf_pred[[\"CM_pred_\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of new file should be 139x141 because we add 'Label' og 'Ensemble_pred', mens Subgruop_ finnes fra fÃ¸r\n",
    "final_df = pd.concat([rf_pred, preds_ensemble], axis=1)\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv( RESULTS_DIR / '3.1-random_forest_n_ensemble_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking confusion matrix from Random Forest prediction\n",
    "TN_teller = 0\n",
    "FP_teller = 0\n",
    "FN_teller = 0\n",
    "TP_teller = 0\n",
    "\n",
    "for i in final_df.index:\n",
    "    if final_df.loc[i,'CM_pred_'] == 'TN':\n",
    "        TN_teller += 1\n",
    "    elif final_df.loc[i,'CM_pred_'] == 'FP':\n",
    "        FP_teller += 1\n",
    "    elif final_df.loc[i,'CM_pred_'] == 'FN':\n",
    "        FN_teller += 1\n",
    "    elif final_df.loc[i,'CM_pred_'] == 'TP':\n",
    "        TP_teller += 1\n",
    "        \n",
    "print(f\"Classification labels from Random Forest prediction on test set:\") \n",
    "print(f\"True Negatives: {TN_teller}\")\n",
    "print(f\"False Positives: {FP_teller}\")\n",
    "print(f\"False Negatives: {FN_teller}\")\n",
    "print(f\"True Positives: {TP_teller}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking confusion matrix from ENSEMBLE prediction\n",
    "tn_teller = 0\n",
    "fp_teller = 0\n",
    "fn_teller = 0\n",
    "tp_teller = 0\n",
    "\n",
    "for i in final_df.index:\n",
    "    if final_df.loc[i,'Ens_pred'] == 'TN_':\n",
    "        tn_teller += 1\n",
    "    elif final_df.loc[i,'Ens_pred'] == 'FP_':\n",
    "        fp_teller += 1\n",
    "    elif final_df.loc[i,'Ens_pred'] == 'FN_':\n",
    "        fn_teller += 1\n",
    "    elif final_df.loc[i,'Ens_pred'] == 'TP_':\n",
    "        tp_teller += 1\n",
    "        \n",
    "print(f\"Classification labels from ensemble model on test set:\") \n",
    "print(f\"True Negatives: {tn_teller}\")\n",
    "print(f\"False Positives: {fp_teller}\")\n",
    "print(f\"False Negatives: {fn_teller}\")\n",
    "print(f\"True Positives: {tp_teller}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating the two models' overlap in misclassfications of **sMCI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_overlap = 0 \n",
    "for i in final_df.index:\n",
    "    if final_df.loc[i,'Ens_pred'] == 'FP_' and final_df.loc[i,'CM_pred_'] == 'FP':\n",
    "        fp_overlap += 1\n",
    "        \n",
    "print(\"*\"*90)\n",
    "print(f\"Random Forest: misclassified {FP_teller} sMCI subjects as cAD.\")\n",
    "print(f\"Ensemblet: misclassified {fp_teller} sMCI subjects as converters.\")\n",
    "print()\n",
    "print(f\"Of these misclassifications the models overlapped {fp_overlap} deltagere.\")\n",
    "print(\"*\"*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying indexes for FP subjects where the models did not overlap  (sMCI --> FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misclassified as sMCI by the Ensemble and correctly classified by the Random Forest\n",
    "indeksList_fp_ensemble = []\n",
    "\n",
    "for i in final_df.index:\n",
    "    if final_df.loc[i,'Ens_pred'] == 'FP_' and final_df.loc[i,'CM_pred_'] == 'TN':\n",
    "        indeksList_fp_ensemble.append(i)\n",
    "        \n",
    "print(\"*\"*100)      \n",
    "print(f\"Subjects with the {len(indeksList_fp_ensemble)} following indices {indeksList_fp_ensemble} were correctly\")\n",
    "print(\"classified by the RF and missclassified by the ensemble\")\n",
    "print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misclassified as sMCI by the Random Forest and correctly by the Ensemble\n",
    "indeksList_fp_rf = []\n",
    "for i in final_df.index:\n",
    "    if final_df.loc[i,'Ens_pred'] == 'TN_' and final_df.loc[i,'CM_pred_'] == 'FP':\n",
    "        indeksList_fp_rf.append(i)\n",
    "        \n",
    "print(\"*\"*100)\n",
    "print(f\"Subjects with the {len(indeksList_fp_rf)} following indices {indeksList_fp_rf} were correctly\")\n",
    "print(\"classified by the ensemble and miscassified by the Random Forest\")\n",
    "print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating the two models' overlap i misclassfications of **cAD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_overlap = 0 \n",
    "\n",
    "for i in final_df.index:\n",
    "    if final_df.loc[i,'Ens_pred'] == 'FN_' and final_df.loc[i,'CM_pred_'] == 'FN':\n",
    "        fn_overlap += 1\n",
    "        \n",
    "print(\"*\"*90)\n",
    "print(f\"Random Forest: misclassified {FN_teller} cAD subjects as stabile.\")\n",
    "print(f\"Ensemblet: misclassified {fn_teller} cAD as stabile.\")\n",
    "print()\n",
    "print(f\"Of these misclassifications, the models overlapped on {fn_overlap} subjects.\")\n",
    "print(\"*\"*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying indexes for FP subjects where the models did not overlap (cAD --> FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subjects misclassified as FN by ensemble, and correctly classified as TP by the random forest:\n",
    "indeksList_fn_ensemble = []\n",
    "for i in final_df.index:\n",
    "    if final_df.loc[i,'Ens_pred'] == 'FN_' and final_df.loc[i,'CM_pred_'] == 'TP':\n",
    "        indeksList_fn_ensemble.append(i)\n",
    "        \n",
    "print(\"*\"*100)\n",
    "\n",
    "print(f\"Subjects with the {len(indeksList_fn_ensemble)} following indecies {indeksList_fn_ensemble} were correctly\")\n",
    "print(\"classified by RF and misclassified by the ensemblet\")\n",
    "print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subjects misclassified as FN by the random forest, and correctly classified as TP by the ensemble:\n",
    "indeksList_fn_rf = []\n",
    "for i in final_df.index:\n",
    "    if final_df.loc[i,'Ens_pred'] == 'TP_' and final_df.loc[i,'CM_pred_'] == 'FN':\n",
    "        indeksList_fn_rf.append(i)\n",
    "        \n",
    "print(\"*\"*100)\n",
    "print(f\"Subjects with the {len(indeksList_fn_rf)} following {indeksList_fn_rf} were ble correctly\")\n",
    "print(\"classified av ensemblet, men feilaktig klassifisert av RF\")\n",
    "print(\"*\"*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mciCopy",
   "language": "python",
   "name": "mcicopy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
